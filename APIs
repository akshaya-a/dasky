class AMLCluster:
    def __init__(self, workspace, compute, node_count, environment_name, experiment_name, use_existing_run=False):
        self.workspace=workspace
        self.compute=compute
        self.node_count=node_count
        self.environment_name=environment_name
        self.experiment_name=experiment_name
        self.use_existing_run=use_existing_run
        self.workers_list=[]
        self.run=None
        self.dashboard_link=""
        self.create_cluster()
        
    def create_cluster(self):  
        if(self.node_count<=0): # throw exception here
            raise ValueError('node_count is not valid')
        #set up environment
        if self.environment_name not in self.workspace.environments:
            env=Environment.from_existing_conda_environment(self.environment_name, 'azureml_py36')
            env.python.conda_dependencies.add_pip_package('mpi4py')
            env = env.register(ws)
        else:
            env = self.workspace.environments[self.environment_name]

        #submit run
        exp = Experiment(self.workspace, self.experiment_name)
        run=None
        if self.use_existing_run==True: #find run with scheduler
            runs=exp.get_runs()
            try:
                run=next(x for i,x in enumerate(runs) if ('scheduler' in x.get_metrics() and x.get_status() == 'Running'))
            except StopIteration:
                run=None
                print("no exisitng run with scheduler.")
        if not run:
            print("Creating new run instance...")
            est = Estimator(
                'setup',
                compute_target=self.compute,
                entry_script='start.py',
                environment_definition=env,
                script_params={'--datastore': self.workspace.get_default_datastore()},
                node_count=1, # start scheduler first
                distributed_training=MpiConfiguration()
            )
            run = exp.submit(est)
            print("waiting for scheduler ")
            while run.get_status() != 'Canceled' and 'scheduler' not in run.get_metrics():
                print('.', end ="")
                time.sleep(5)
            
        self.run=run
        self.scale(self.node_count-1) # create workers

        #return run
    
    def connect_cluster(self):
        if not self.run: 
            sys.exit("run doesn't exist.")
        dashboard_port=4242

        if self.run.get_status() == 'Canceled':
            print('\nRun was canceled')
        else:
            print(f'\nSetting up port forwarding...')
            os.system(f'killall socat') # kill all socat processes - cleans up previous port forward setups 
            os.system(f'setsid socat tcp-listen:{dashboard_port},reuseaddr,fork tcp:{self.run.get_metrics()["dashboard"]} &')
            print(f'Cluster is ready to use.')

        c = Client(f'tcp://{self.run.get_metrics()["scheduler"]}')
        print(f'\n\n{c}')

        #get the dashboard link 
        dashboard_url = f'https://{socket.gethostname()}-{dashboard_port}.{self.workspace.get_details()["location"]}.instances.azureml.net/status'
        HTML(f'<a href="{dashboard_url}">Dashboard link</a>')
        
        self.dashboard_link=dashboard_url

        return c
    
    def scale(self, workers=1):
        count=len(self.workers_list)
        if count < workers:
            self.scale_up(workers-count)
        elif count > workers:
            self.scale_down(count-workers)
        else:
            print("Number of workers: %s", workers)
    
    def scale_up(self, workers=1):
        for i in range(workers):
            est = Estimator(
                'setup',
                compute_target=self.compute,
                entry_script='childRun.py', # pass scheduler ip from parent run
                environment_definition=self.workspace.environments[self.environment_name],
                script_params={'--datastore': self.workspace.get_default_datastore(), '--scheduler': self.run.get_metrics()["scheduler"]},
                node_count=1,
                distributed_training=MpiConfiguration()
            )

            child_run = Experiment(self.workspace, experiment_name).submit(est)
            self.workers_list.append(child_run)
            
    #scale down
    def scale_down(self, workers=1):
         for i in range(workers):
                if self.workers_list:
                    child_run=self.workers_list.pop(0) #deactive oldest workers
                    child_run.cancel()
                else:
                    print("All scaled workers are removed.")
    
    # close cluster
    def close(self):
        while self.workers_list:
            child_run=self.workers_list.pop()
            child_run.cancel()
        if self.run:
            self.run.cancel()
        print("Scheduler and workers are disconnected.")
        
    # get run instance
    def get_run(self):
        return self.run
    
    # get dashboard link
    def get_dashboard_link(self):
        return self.dashboard_link
    
    # get jupyter_link
    def get_jupyter_link(self):
        print("under construction ... ")
        
    # get logs
    def logs(self):
        return self.run.get_all_logs()
