{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start Interactive Dask Cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install --upgrade git+https://github.com/drabastomek/dask-cloudprovider"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**RESTART YOUR KERNEL**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports\n",
    "\n",
    "Import all packages used in this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from azureml.widgets import RunDetails\n",
    "from azureml.core.compute import ComputeTarget, AmlCompute\n",
    "from azureml.core import Workspace, Experiment, Datastore, Dataset, Environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Azure ML setup\n",
    "\n",
    "Get the workspace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Workspace.create(name='eus-azureml', subscription_id='6560575d-fa06-4e7d-95fb-f962e74efd7a', resource_group='cody-rg')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ws = Workspace.from_config()\n",
    "ws"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Enter your name\n",
    "\n",
    "Enter your name and virtual network information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Name: dask\n",
      "\n",
      "vNET RG: cody-rg\n",
      "vNET name: wifi-eastus\n",
      "vNET subnet name: default\n",
      "\n",
      "Compute target: dask-ct\n",
      "Environment name: dask-env\n",
      "\n"
     ]
    }
   ],
   "source": [
    "### name\n",
    "name        = 'dask'                                    # REPLACE\n",
    "\n",
    "### vnet settings\n",
    "vnet_rg     = ws.resource_group                         # replace if needed\n",
    "vnet_name   = f'wifi-{ws.get_details()[\"location\"]}'    # replace if needed\n",
    "subnet_name = 'default'                                 # replace if needed\n",
    "\n",
    "### azure ml names \n",
    "ct_name     = f'{name}-ct'\n",
    "env_name    = f'{name}-env'\n",
    "\n",
    "### trust but verify\n",
    "verify = f'''\n",
    "Name: {name}\n",
    "\n",
    "vNET RG: {vnet_rg}\n",
    "vNET name: {vnet_name}\n",
    "vNET subnet name: {subnet_name}\n",
    "\n",
    "Compute target: {ct_name}\n",
    "Environment name: {env_name}\n",
    "'''\n",
    "\n",
    "print(verify)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create VM pool\n",
    "\n",
    "Create Azure ML VM pool for creating remote dask cluster(s)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating\n",
      "Succeeded\n",
      "AmlCompute wait for completion finished\n",
      "Minimum number of nodes requested have been provisioned\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AmlCompute(workspace=Workspace.create(name='eus-azureml', subscription_id='6560575d-fa06-4e7d-95fb-f962e74efd7a', resource_group='cody-rg'), name=dask-ct, id=/subscriptions/6560575d-fa06-4e7d-95fb-f962e74efd7a/resourceGroups/cody-rg/providers/Microsoft.MachineLearningServices/workspaces/eus-azureml/computes/dask-ct, type=AmlCompute, provisioning_state=Succeeded, location=eastus, tags=None)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if ct_name not in ws.compute_targets:\n",
    "    # create config for Azure ML cluster\n",
    "    # change properties as needed\n",
    "    config = AmlCompute.provisioning_configuration(\n",
    "             vm_size                       = 'STANDARD_DS13_V2', # 8 core 56 GiB 112 SSD \n",
    "             min_nodes                     = 0,\n",
    "             max_nodes                     = 100,\n",
    "             vnet_resourcegroup_name       = vnet_rg,              \n",
    "             vnet_name                     = vnet_name,         \n",
    "             subnet_name                   = subnet_name,          \n",
    "             idle_seconds_before_scaledown = 300\n",
    "    )\n",
    "    ct = ComputeTarget.create(ws, ct_name, config)\n",
    "    ct.wait_for_completion(show_output=True)    \n",
    "else:\n",
    "    ct = ws.compute_targets[ct_name]\n",
    "    \n",
    "ct"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mount Compute Instance code fileshare\n",
    "\n",
    "This will create the compute instance code fileshare as a datastore. The default name `code-391ff5ac-6576-460f-ba4d-7e03433c68b6` and has the same credentials as the default fileshare for the workspace. This will be mounted for easy access to notebooks on the cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "codefileshare = 'codefileshare'\n",
    "\n",
    "if codefileshare not in ws.datastores:\n",
    "    Datastore.register_azure_file_share(ws, codefileshare,\n",
    "                                        'code-391ff5ac-6576-460f-ba4d-7e03433c68b6',                    \n",
    "                                        account_name = ws.datastores['workspacefilestore'].account_name, \n",
    "                                        account_key  = ws.datastores['workspacefilestore'].account_key   \n",
    "                                       )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get data\n",
    "\n",
    "This will get NOAA ISD Weather data which is used in the demo. If you already have data in Blob or ALDSv1v2 you want to use, skip this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 236 ms, sys: 63.7 ms, total: 300 ms\n",
      "Wall time: 12.5 s\n",
      "CPU times: user 82.3 ms, sys: 13.8 ms, total: 96 ms\n",
      "Wall time: 9.66 s\n",
      "CPU times: user 77 ms, sys: 10.5 ms, total: 87.5 ms\n",
      "Wall time: 9.6 s\n",
      "CPU times: user 87.9 ms, sys: 14.6 ms, total: 103 ms\n",
      "Wall time: 9.85 s\n",
      "CPU times: user 71.7 ms, sys: 0 ns, total: 71.7 ms\n",
      "Wall time: 9.65 s\n",
      "CPU times: user 81.8 ms, sys: 2.58 ms, total: 84.4 ms\n",
      "Wall time: 9.93 s\n",
      "CPU times: user 73.1 ms, sys: 14.2 ms, total: 87.3 ms\n",
      "Wall time: 10.3 s\n",
      "CPU times: user 84.1 ms, sys: 754 µs, total: 84.8 ms\n",
      "Wall time: 11.8 s\n",
      "CPU times: user 95.7 ms, sys: 554 µs, total: 96.2 ms\n",
      "Wall time: 6.58 s\n",
      "CPU times: user 70.5 ms, sys: 5.5 ms, total: 76 ms\n",
      "Wall time: 7.89 s\n",
      "CPU times: user 78.4 ms, sys: 8.39 ms, total: 86.8 ms\n",
      "Wall time: 8.19 s\n",
      "CPU times: user 87.8 ms, sys: 9.73 ms, total: 97.5 ms\n",
      "Wall time: 9.75 s\n",
      "CPU times: user 95.5 ms, sys: 0 ns, total: 95.5 ms\n",
      "Wall time: 3.3 s\n"
     ]
    }
   ],
   "source": [
    "dsetdata = 'noaa-isd-files'\n",
    "data_url = 'https://azureopendatastorage.blob.core.windows.net/isdweatherdatacontainer/ISDWeather'\n",
    "\n",
    "if dsetdata not in ws.datasets:\n",
    "    os.system('sudo chmod 777 /mnt')\n",
    "    for year in range(2008, 2020+1):\n",
    "        ds = Dataset.File.from_files(f'{data_url}/year={year}/month=*/*.parquet', validate=False)\n",
    "        print('Downloading...')\n",
    "        %time ds.download(f'/mnt/data/isd/year={year}', overwrite=True)\n",
    "    print('Uploading...')\n",
    "    %time ws.get_default_datastore().upload('/mnt/data/isd', '/noaa-isd', show_progress=False)\n",
    "    ds = Dataset.File.from_files((ws.get_default_datastore(), '/noaa-isd/**/*.parquet'))\n",
    "    ds = ds.register(ws, dsetdata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start cluster\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dask_cloudprovider import AzureMLCluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "packages = ['mpi4py',\n",
    "            'distributed',\n",
    "            'dask[complete]',\n",
    "            'dask-ml[complete]',\n",
    "            'fastparquet',\n",
    "            'pyarrow',\n",
    "            'jupyterlab',\n",
    "            'joblib',\n",
    "            'notebook',\n",
    "            'adlfs', \n",
    "            'fsspec', \n",
    "            'azureml-sdk',\n",
    "            'lz4']\n",
    "\n",
    "env = Environment(name=env_name)\n",
    "\n",
    "for package in packages:\n",
    "    env.python.conda_dependencies.add_pip_package(package)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - This compute target type doesn't support non-Docker runs; overriding run configuration enable Docker.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "############################## Setting up cluster ##############################\n",
      "########################## Submitting the experiment ###########################\n",
      "####################### Waiting for scheduler node's IP ########################\n",
      ".................................................................................................................................................................................................................................................................\n",
      "\n",
      "\n",
      "########################### Scheduler: 10.2.0.5:8786 ###########################\n",
      "############################### On the same VNET ###############################\n",
      "########################### Connections established ############################\n",
      "############################ Scaling to 10 workers #############################\n",
      "############################### Scaling is done ################################\n"
     ]
    }
   ],
   "source": [
    "cluster = AzureMLCluster(ws, \n",
    "                         ct, \n",
    "                         env, \n",
    "                         jupyter=True, \n",
    "                         initial_node_count=10,\n",
    "                         datastores=[ws.datastores[datastore] for datastore in ws.datastores]\n",
    "                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table style=\"width:100%\"><tr><th>Experiment</th><th>Id</th><th>Type</th><th>Status</th><th>Details Page</th><th>Docs Page</th></tr><tr><td>dask-cloudprovider</td><td>dask-cloudprovider_1582513353_456b702c</td><td>azureml.scriptrun</td><td>Running</td><td><a href=\"https://ml.azure.com/experiments/dask-cloudprovider/runs/dask-cloudprovider_1582513353_456b702c?wsid=/subscriptions/6560575d-fa06-4e7d-95fb-f962e74efd7a/resourcegroups/cody-rg/workspaces/eus-azureml\" target=\"_blank\" rel=\"noopener\">Link to Azure Machine Learning studio</a></td><td><a href=\"https://docs.microsoft.com/en-us/python/api/azureml-core/azureml.core.script_run.ScriptRun?view=azure-ml-py\" target=\"_blank\" rel=\"noopener\">Link to Documentation</a></td></tr></table>"
      ],
      "text/plain": [
       "Run(Experiment: dask-cloudprovider,\n",
       "Id: dask-cloudprovider_1582513353_456b702c,\n",
       "Type: azureml.scriptrun,\n",
       "Status: Running)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cluster.run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster.scale(25) # need more than default quota for this "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cacc2f9512234706809f3e691062bdaa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<h2>AzureMLCluster</h2>'), HBox(children=(HTML(value='\\n<div>\\n  <style scoped>\\n  …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from dask.distributed import Client\n",
    "#c = Client(cluster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cluster.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class AzureMLCluster in module dask_cloudprovider.providers.azure.azureml:\n",
      "\n",
      "class AzureMLCluster(distributed.deploy.cluster.Cluster)\n",
      " |  Deploy a Dask cluster using Azure ML\n",
      " |  \n",
      " |  This creates a dask scheduler and workers on an Azure ML Compute Target.\n",
      " |  \n",
      " |  Parameters\n",
      " |  ----------\n",
      " |  workspace: azureml.core.Workspace (required)\n",
      " |      Azure ML Workspace - see https://aka.ms/azureml/workspace\n",
      " |  \n",
      " |  compute_target: azureml.core.ComputeTarget (required)\n",
      " |      Azure ML Compute Target - see https://aka.ms/azureml/computetarget\n",
      " |  \n",
      " |  environment_definition: azureml.core.Environment (required)\n",
      " |      Azure ML Environment - see https://aka.ms/azureml/environments\n",
      " |  \n",
      " |  experiment_name: str (optional)\n",
      " |      The name of the Azure ML Experiment used to control the cluster.\n",
      " |  \n",
      " |      Defaults to ``dask-cloudprovider``.\n",
      " |  \n",
      " |  initial_node_count: int (optional)\n",
      " |      The initial number of nodes for the Dask Cluster.\n",
      " |  \n",
      " |      Defaults to ``1``.\n",
      " |  \n",
      " |  jupyter: bool (optional)\n",
      " |      Flag to start JupyterLab session on the headnode of the cluster.\n",
      " |  \n",
      " |      Defaults to ``False``.\n",
      " |  \n",
      " |  jupyter_port: int (optional)\n",
      " |      Port on headnode to use for hosting JupyterLab session.\n",
      " |  \n",
      " |      Defaults to ``9000``.\n",
      " |  \n",
      " |  dashboard_port: int (optional)\n",
      " |      Port on headnode to use for hosting Dask dashboard.\n",
      " |  \n",
      " |      Defaults to ``9001``.\n",
      " |  \n",
      " |  scheduler_port: int (optional)\n",
      " |      Port to map the scheduler port to via SSH-tunnel if machine not on the same VNET.\n",
      " |  \n",
      " |      Defaults to ``9002``.\n",
      " |  \n",
      " |  additional_ports: list[tuple[int, int]] (optional)\n",
      " |      Additional ports to forward. This requires a list of tuples where the first element\n",
      " |      is the port to open on the headnode while the second element is the port to map to\n",
      " |      or forward via the SSH-tunnel.\n",
      " |  \n",
      " |      Defaults to ``[]``.\n",
      " |  \n",
      " |  admin_username: str (optional)\n",
      " |      Username of the admin account for the AzureML Compute.\n",
      " |      Required for runs that are not on the same VNET. Defaults to empty string.\n",
      " |      Throws Exception if machine not on the same VNET.\n",
      " |  \n",
      " |      Defaults to ``\"\"``.\n",
      " |  \n",
      " |  admin_ssh_key: str (optional)\n",
      " |      Location of the SSH secret key used when creating the AzureML Compute.\n",
      " |      The key should be passwordless if run from a Jupyter notebook.\n",
      " |      The ``id_rsa`` file needs to have 0700 permissions set.\n",
      " |      Required for runs that are not on the same VNET. Defaults to empty string.\n",
      " |      Throws Exception if machine not on the same VNET.\n",
      " |  \n",
      " |      Defaults to ``\"\"``.\n",
      " |  \n",
      " |  datastores: List[str] (optional)\n",
      " |      List of Azure ML Datastores to be mounted on the headnode -\n",
      " |      see https://aka.ms/azureml/data and https://aka.ms/azureml/datastores.\n",
      " |  \n",
      " |      Defaults to ``[]``. To mount all datastores in the workspace,\n",
      " |      set to ``[ws.datastores[datastore] for datastore in ws.datastores]``.\n",
      " |  \n",
      " |  asynchronous: bool (optional)\n",
      " |      Flag to run jobs asynchronously.\n",
      " |  \n",
      " |  **kwargs: dict\n",
      " |      Additional keyword arguments.\n",
      " |  \n",
      " |  Example | ``AzureMLCluster`` for Dask Client.\n",
      " |  See https://aka.ms/azureml/dask.\n",
      " |  ----------\n",
      " |  ```\n",
      " |  from azureml.core import Workspace\n",
      " |  from dask.distributed import Client\n",
      " |  from dask_cloudprovider import AzureMLCluster\n",
      " |  \n",
      " |  ws = Workspace.from_config()\n",
      " |  \n",
      " |  cluster = AzureMLCluster(ws,\n",
      " |                           ws.compute_targets['dask-ct'],\n",
      " |                           ws.environments['dask-env'])\n",
      " |  \n",
      " |  client = Client(cluster)\n",
      " |  ```\n",
      " |  \n",
      " |  Example | ``AzureMLCluster`` for interactive JupyterLab session.\n",
      " |  See https://aka.ms/azureml/dask.\n",
      " |  ----------\n",
      " |  ```\n",
      " |  from azureml.core import Workspace\n",
      " |  from dask_cloudprovider import AzureMLCluster\n",
      " |  \n",
      " |  ws = Workspace.from_config()\n",
      " |  \n",
      " |  cluster = AzureMLCluster(ws,\n",
      " |                           ws.compute_targets['dask-ct'],\n",
      " |                           ws.environments['dask-env'],\n",
      " |                           datastores=list(ws.datastores),\n",
      " |                           jupyter=True)\n",
      " |  \n",
      " |  print(cluster.jupyter_link)\n",
      " |  print(cluster.dashboard_link)\n",
      " |  ```\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      AzureMLCluster\n",
      " |      distributed.deploy.cluster.Cluster\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, workspace, compute_target, environment_definition, experiment_name=None, initial_node_count=None, jupyter=None, jupyter_port=None, dashboard_port=None, scheduler_port=None, additional_ports=None, admin_username=None, admin_ssh_key=None, datastores=None, code_store=None, asynchronous=False, **kwargs)\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |  \n",
      " |  close(self)\n",
      " |      Close the cluster. All Azure ML Runs corresponding to the scheduler\n",
      " |      and worker processes will be completed. The Azure ML Compute Target will\n",
      " |      return to its minimum number of nodes after its idle time before scaledown.\n",
      " |      \n",
      " |      Example\n",
      " |      ----------\n",
      " |      cluster.close()\n",
      " |  \n",
      " |  create_cluster(self)\n",
      " |  \n",
      " |  get_defaults(self)\n",
      " |  \n",
      " |  print_links_ComputeVM(self)\n",
      " |  \n",
      " |  scale(self, workers=1)\n",
      " |      Scale the cluster. We can add or reduce the number workers\n",
      " |      of a given configuration\n",
      " |      \n",
      " |      Example\n",
      " |      ----------\n",
      " |      ```python\n",
      " |      cluster.scale(2)\n",
      " |      ```\n",
      " |  \n",
      " |  scale_down(self, workers=1)\n",
      " |      # scale down\n",
      " |  \n",
      " |  scale_up(self, workers=1)\n",
      " |      # scale up\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors defined here:\n",
      " |  \n",
      " |  dashboard_link\n",
      " |      Link to Dask dashboard.\n",
      " |      \n",
      " |      Example\n",
      " |      ----------\n",
      " |      print(cluster.dashboard_link)\n",
      " |  \n",
      " |  jupyter_link\n",
      " |      Link to JupyterLab on running on the headnode of the cluster.\n",
      " |      Set ``jupyter=True`` when creating the ``AzureMLCluster``.\n",
      " |      \n",
      " |      Example\n",
      " |      ----------\n",
      " |      print(cluster.jupyter_link)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from distributed.deploy.cluster.Cluster:\n",
      " |  \n",
      " |  __aenter__(self)\n",
      " |  \n",
      " |  __aexit__(self, typ, value, traceback)\n",
      " |  \n",
      " |  __del__(self)\n",
      " |  \n",
      " |  __repr__(self)\n",
      " |      Return repr(self).\n",
      " |  \n",
      " |  adapt(self, Adaptive=<class 'distributed.deploy.adaptive.Adaptive'>, **kwargs) -> distributed.deploy.adaptive.Adaptive\n",
      " |      Turn on adaptivity\n",
      " |      \n",
      " |      For keyword arguments see dask.distributed.Adaptive\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> cluster.adapt(minimum=0, maximum=10, interval='500ms')\n",
      " |  \n",
      " |  logs(self, scheduler=True, workers=True)\n",
      " |      Return logs for the scheduler and workers\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      scheduler : boolean\n",
      " |          Whether or not to collect logs for the scheduler\n",
      " |      workers : boolean or Iterable[str], optional\n",
      " |          A list of worker addresses to select.\n",
      " |          Defaults to all workers if `True` or no workers if `False`\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      logs: Dict[str]\n",
      " |          A dictionary of logs, with one item for the scheduler and one for\n",
      " |          each worker\n",
      " |  \n",
      " |  sync(self, func, *args, asynchronous=None, callback_timeout=None, **kwargs)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from distributed.deploy.cluster.Cluster:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      " |  \n",
      " |  asynchronous\n",
      " |  \n",
      " |  observed\n",
      " |  \n",
      " |  plan\n",
      " |  \n",
      " |  requested\n",
      " |  \n",
      " |  scheduler_address\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(AzureMLCluster)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6 - AzureML",
   "language": "python",
   "name": "python3-azureml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
